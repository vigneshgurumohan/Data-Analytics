import openai
from langchain_core.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_core.output_parsers import BaseOutputParser
from langchain_openai import ChatOpenAI
from pydantic import BaseModel
import logging
import string
import json
import pandas as pd
from itertools import islice
from typing import List
from langchain.pydantic_v1 import Field, validator
from langchain.output_parsers import PydanticOutputParser

# Load CSV file
file_path = 'mapping_raw.csv'  # Replace with your actual CSV file path
df = pd.read_csv(file_path)

# Helper Function to Chunk Lists
def chunk_list(data_list, chunk_size):
    """Splits a list into chunks of a given size."""
    it = iter(data_list)
    return iter(lambda: list(islice(it, chunk_size)), [])

# Pydantic Models
class MerchantComparisonResult(BaseModel):
    decision: int = Field(description="Score between 0-100 for each comparison between raw and cleaned name")
    reason: str = Field(description="Descriptive reasoning for the decision taken")

class FinalMerchantComparison(BaseModel):
    results: List[MerchantComparisonResult] = Field(description="Final output of each comparison between raw and cleaned name")

# Batch Comparison with Reasoning
def compare_batch_with_reasoning(cdf_name: str, raw_names_batch: List[str]):
    prompt = (
        f"You are an excellent name cleaning and matching expert. You will be provided with two sets of information:\n"
        f"1. **Cleaned Name**: '{cdf_name}' - This is the cleaned, standardized merchant name.\n"
        f"2. **List of Raw Names**: {raw_names_batch} - A list of raw, uncleaned merchant names.\n"
        f"Your task is to compare each raw name with the cleaned name to see if the sequence of characters are close matches.\n"
        f"Provide a match strength score (0 to 100) and a reason in less than 5 words for each comparison."
        f"Format your response strictly as: {{format_instructions}}"
    )
    try:
        # Initialize the chat model
        chat = ChatOpenAI(
            model="gpt-3.5-turbo-16k",
            max_tokens=3000,
            temperature=0,
            openai_api_key="api-key"
        )
        parser = PydanticOutputParser(pydantic_object=FinalMerchantComparison)
        chain = LLMChain(
            llm=chat,
            prompt=PromptTemplate(
                input_variables=["prompt"],
                partial_variables={"format_instructions": parser.get_format_instructions()},
                template=prompt
            )
        )
        response = chain.invoke({"prompt": prompt})
        parsed_response = json.loads(response["text"])
        return parsed_response
    except Exception as e:
        logging.error(f"Error processing {cdf_name}: {str(e)}")
        return [{"decision": "error", "reason": f"Error: {str(e)}"} for _ in raw_names_batch]

# Sanitize Names
def sanitize_name(name):
    """Remove non-printable characters and extra spaces."""
    return ''.join(c for c in str(name) if c in string.printable).strip()

# Processing Data
result_rows = []
for cdf_name in df['cdf_merchant_name'].unique():
    raw_names = df[df['cdf_merchant_name'] == cdf_name]['raw_name'].apply(sanitize_name).tolist()
    raw_name_chunks = chunk_list(raw_names, 10)
    for raw_names_batch in raw_name_chunks:
        comparisons = compare_batch_with_reasoning(cdf_name, raw_names_batch)
        for raw_name, comparison in zip(raw_names_batch, comparisons['results']):
            result_rows.append({
                "cdf_merchant_name": cdf_name,
                "raw_name": raw_name,
                "mapped": comparison.get('decision'),
                "reason": comparison.get('reason', '')
            })

# Save Results
result_df = pd.DataFrame(result_rows)
result_df.to_csv('output2.csv', index=False)
